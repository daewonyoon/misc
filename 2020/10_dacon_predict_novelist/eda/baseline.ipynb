{
 "metadata": {
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5-final"
  },
  "orig_nbformat": 2,
  "kernelspec": {
   "name": "Python 3.8.5 64-bit ('v3864')",
   "display_name": "Python 3.8.5 64-bit ('v3864')",
   "metadata": {
    "interpreter": {
     "hash": "9602f2835335299274efac487fb325798245bbf5d002bbd859b78dff5c91fecf"
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2,
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "import re\n",
    "\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dat_dir_path()->str:\n",
    "    return os.path.abspath('../dat')\n",
    "\n",
    "def get_train_csv_path()->str:\n",
    "    dat_dir = get_dat_dir_path()\n",
    "    # print(dat_dir)\n",
    "    return os.path.join(dat_dir, \"train.csv\")\n",
    "\n",
    "def get_test_csv_path()->str:\n",
    "    dat_dir = get_dat_dir_path()\n",
    "    return os.path.join(dat_dir, \"test_x.csv\")\n",
    "\n",
    "def get_sample_sub_path()->str:\n",
    "    dat_dir = get_dat_dir_path()\n",
    "    return os.path.join(dat_dir, \"sample_submission.csv\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv(get_train_csv_path())\n",
    "test = pd.read_csv(get_test_csv_path())\n",
    "sample_submission = pd.read_csv(get_sample_sub_path())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# preprocesscing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha_num(txt:str)->str:\n",
    "    return re.sub(r\"[^A-Za-z0-9 ]\", \"\", txt)\n",
    "\n",
    "train[\"text\"] = train[\"text\"].apply(alpha_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       index                                               text  author\n",
       "0          0  He was almost choking There was so much so muc...       3\n",
       "1          1                 Your sister asked for it I suppose       2\n",
       "2          2   She was engaged one day as she walked in peru...       1\n",
       "3          3  The captain was in the porch keeping himself c...       4\n",
       "4          4  Have mercy gentlemen odin flung up his hands D...       3\n",
       "...      ...                                                ...     ...\n",
       "54874  54874  Is that you Mr Smith odin whispered I hardly d...       2\n",
       "54875  54875  I told my plan to the captain and between us w...       4\n",
       "54876  54876   Your sincere wellwisher friend and sister LUC...       1\n",
       "54877  54877               Then you wanted me to lend you money       3\n",
       "54878  54878  It certainly had not occurred to me before but...       0\n",
       "\n",
       "[54879 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>He was almost choking There was so much so muc...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>Your sister asked for it I suppose</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>She was engaged one day as she walked in peru...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>The captain was in the porch keeping himself c...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>Have mercy gentlemen odin flung up his hands D...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54874</th>\n      <td>54874</td>\n      <td>Is that you Mr Smith odin whispered I hardly d...</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>54875</th>\n      <td>54875</td>\n      <td>I told my plan to the captain and between us w...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>54876</th>\n      <td>54876</td>\n      <td>Your sincere wellwisher friend and sister LUC...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>54877</th>\n      <td>54877</td>\n      <td>Then you wanted me to lend you money</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>54878</th>\n      <td>54878</td>\n      <td>It certainly had not occurred to me before but...</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>54879 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 6
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwords = [ \"a\", \"about\", \"above\", \"after\", \"again\", \"against\", \"all\", \"am\", \"an\", \"and\", \"any\", \"are\", \"as\", \n",
    "             \"at\", \"be\", \"because\", \"been\", \"before\", \"being\", \"below\", \"between\", \"both\", \"but\", \"by\", \"could\", \n",
    "             \"did\", \"do\", \"does\", \"doing\", \"down\", \"during\", \"each\", \"few\", \"for\", \"from\", \"further\", \"had\", \"has\", \n",
    "             \"have\", \"having\", \"he\", \"he'd\", \"he'll\", \"he's\", \"her\", \"here\", \"here's\", \"hers\", \"herself\", \"him\", \"himself\", \n",
    "             \"his\", \"how\", \"how's\", \"i\", \"i'd\", \"i'll\", \"i'm\", \"i've\", \"if\", \"in\", \"into\", \"is\", \"it\", \"it's\", \"its\", \"itself\", \n",
    "             \"let's\", \"me\", \"more\", \"most\", \"my\", \"myself\", \"nor\", \"of\", \"on\", \"once\", \"only\", \"or\", \"other\", \"ought\", \"our\", \"ours\", \n",
    "             \"ourselves\", \"out\", \"over\", \"own\", \"same\", \"she\", \"she'd\", \"she'll\", \"she's\", \"should\", \"so\", \"some\", \"such\", \"than\", \"that\", \n",
    "             \"that's\", \"the\", \"their\", \"theirs\", \"them\", \"themselves\", \"then\", \"there\", \"there's\", \"these\", \"they\", \"they'd\", \"they'll\", \n",
    "             \"they're\", \"they've\", \"this\", \"those\", \"through\", \"to\", \"too\", \"under\", \"until\", \"up\", \"very\", \"was\", \"we\", \"we'd\", \"we'll\", \n",
    "             \"we're\", \"we've\", \"were\", \"what\", \"what's\", \"when\", \"when's\", \"where\", \"where's\", \"which\", \"while\", \"who\", \"who's\", \"whom\", \n",
    "             \"why\", \"why's\", \"with\", \"would\", \"you\", \"you'd\", \"you'll\", \"you're\", \"you've\", \"your\", \"yours\", \"yourself\", \"yourselves\" ]\n",
    "\n",
    "def remove_stopwords(text:str) -> str:\n",
    "    final_txt = []\n",
    "    for i in text.split():\n",
    "        if i.strip().lower() not in stopwords:\n",
    "            final_txt.append(i.strip())\n",
    "    return \" \".join(final_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "train[\"text\"] = train[\"text\"].apply(alpha_num).apply(remove_stopwords)\n",
    "test[\"text\"] = test[\"text\"].apply(alpha_num).apply(remove_stopwords)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       index                                               text  author\n",
       "0          0  almost choking much much wanted say strange ex...       3\n",
       "1          1                               sister asked suppose       2\n",
       "2          2  engaged one day walked perusing Janes last let...       1\n",
       "3          3  captain porch keeping carefully way treacherou...       4\n",
       "4          4  mercy gentlemen odin flung hands Dont write an...       3\n",
       "...      ...                                                ...     ...\n",
       "54874  54874     Mr Smith odin whispered hardly dared hope come       2\n",
       "54875  54875  told plan captain us settled details accomplis...       4\n",
       "54876  54876         sincere wellwisher friend sister LUCY odin       1\n",
       "54877  54877                                  wanted lend money       3\n",
       "54878  54878               certainly not occurred said Yes like       0\n",
       "\n",
       "[54879 rows x 3 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>text</th>\n      <th>author</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>almost choking much much wanted say strange ex...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>sister asked suppose</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>engaged one day walked perusing Janes last let...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>captain porch keeping carefully way treacherou...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>mercy gentlemen odin flung hands Dont write an...</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>54874</th>\n      <td>54874</td>\n      <td>Mr Smith odin whispered hardly dared hope come</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>54875</th>\n      <td>54875</td>\n      <td>told plan captain us settled details accomplis...</td>\n      <td>4</td>\n    </tr>\n    <tr>\n      <th>54876</th>\n      <td>54876</td>\n      <td>sincere wellwisher friend sister LUCY odin</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>54877</th>\n      <td>54877</td>\n      <td>wanted lend money</td>\n      <td>3</td>\n    </tr>\n    <tr>\n      <th>54878</th>\n      <td>54878</td>\n      <td>certainly not occurred said Yes like</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>54879 rows Ã— 3 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 9
    }
   ],
   "source": [
    "train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train = train[\"text\"].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.array([x for x in train[\"text\"]])\n",
    "x_test = np.array([x for x in test[\"text\"]])\n",
    "y_train = np.array([x for x in train[\"author\"]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# x_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Modeling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab_size = 20000\n",
    "embedding_dim = 100\n",
    "max_length = 500\n",
    "padding_type = \"post\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer(num_words=vocab_size)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "['odin', 'not', 'said', 'no', 'one', 'mr', 'will', 'upon', 'now', 'man']"
      ]
     },
     "metadata": {},
     "execution_count": 17
    }
   ],
   "source": [
    "list(word_index)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_sequence = tokenizer.texts_to_sequences(x_train)\n",
    "train_padded = pad_sequences(train_sequence, padding=padding_type, maxlen=max_length)\n",
    "\n",
    "test_sequence = tokenizer.texts_to_sequences(x_test)\n",
    "test_padded = pad_sequences(test_sequence, padding=padding_type, maxlen=max_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[  141,  7259,    20, ...,     0,     0,     0],\n",
       "       [  217,    58,   221, ...,     0,     0,     0],\n",
       "       [  682,     5,    59, ...,     0,     0,     0],\n",
       "       ...,\n",
       "       [ 2407, 19738,   126, ...,     0,     0,     0],\n",
       "       [  316,  3532,   164, ...,     0,     0,     0],\n",
       "       [  203,     2,   811, ...,     0,     0,     0]])"
      ]
     },
     "metadata": {},
     "execution_count": 19
    }
   ],
   "source": [
    "train_padded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(vocab_size, embedding_dim, input_length=max_length),\n",
    "    tf.keras.layers.GlobalAveragePooling1D(),\n",
    "    tf.keras.layers.Dense(124, activation=\"relu\"),\n",
    "    tf.keras.layers.Dense(5, activation=\"softmax\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Model: \"sequential\"\n_________________________________________________________________\nLayer (type)                 Output Shape              Param #   \n=================================================================\nembedding (Embedding)        (None, 500, 100)          2000000   \n_________________________________________________________________\nglobal_average_pooling1d (Gl (None, 100)               0         \n_________________________________________________________________\ndense (Dense)                (None, 124)               12524     \n_________________________________________________________________\ndense_1 (Dense)              (None, 5)                 625       \n=================================================================\nTotal params: 2,013,149\nTrainable params: 2,013,149\nNon-trainable params: 0\n_________________________________________________________________\nNone\n"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"sparse_categorical_crossentropy\",\n",
    "              optimizer=\"adam\",\n",
    "              metrics=[\"accuracy\"])\n",
    "print(model.summary())            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Epoch 1/20\n",
      "1372/1372 - 8s - loss: 1.5590 - accuracy: 0.2848 - val_loss: 1.4989 - val_accuracy: 0.3237\n",
      "Epoch 2/20\n",
      "1372/1372 - 8s - loss: 1.2886 - accuracy: 0.4550 - val_loss: 1.1787 - val_accuracy: 0.4989\n",
      "Epoch 3/20\n",
      "1372/1372 - 8s - loss: 1.0910 - accuracy: 0.5430 - val_loss: 1.0772 - val_accuracy: 0.5492\n",
      "Epoch 4/20\n",
      "1372/1372 - 10s - loss: 0.9843 - accuracy: 0.6039 - val_loss: 1.0045 - val_accuracy: 0.5983\n",
      "Epoch 5/20\n",
      "1372/1372 - 7s - loss: 0.8727 - accuracy: 0.6687 - val_loss: 0.9318 - val_accuracy: 0.6358\n",
      "Epoch 6/20\n",
      "1372/1372 - 8s - loss: 0.7706 - accuracy: 0.7161 - val_loss: 0.8550 - val_accuracy: 0.6800\n",
      "Epoch 7/20\n",
      "1372/1372 - 8s - loss: 0.6996 - accuracy: 0.7446 - val_loss: 0.8313 - val_accuracy: 0.6911\n",
      "Epoch 8/20\n",
      "1372/1372 - 8s - loss: 0.6453 - accuracy: 0.7648 - val_loss: 0.7959 - val_accuracy: 0.7042\n",
      "Epoch 9/20\n",
      "1372/1372 - 8s - loss: 0.6046 - accuracy: 0.7783 - val_loss: 0.8156 - val_accuracy: 0.7013\n",
      "Epoch 10/20\n",
      "1372/1372 - 9s - loss: 0.5686 - accuracy: 0.7931 - val_loss: 0.7813 - val_accuracy: 0.7084\n",
      "Epoch 11/20\n",
      "1372/1372 - 9s - loss: 0.5379 - accuracy: 0.8041 - val_loss: 0.7950 - val_accuracy: 0.7075\n",
      "Epoch 12/20\n",
      "1372/1372 - 9s - loss: 0.5139 - accuracy: 0.8128 - val_loss: 0.7837 - val_accuracy: 0.7179\n",
      "Epoch 13/20\n",
      "1372/1372 - 8s - loss: 0.4906 - accuracy: 0.8216 - val_loss: 0.7888 - val_accuracy: 0.7201\n",
      "Epoch 14/20\n",
      "1372/1372 - 11s - loss: 0.4759 - accuracy: 0.8271 - val_loss: 0.7956 - val_accuracy: 0.7180\n",
      "Epoch 15/20\n",
      "1372/1372 - 9s - loss: 0.4549 - accuracy: 0.8343 - val_loss: 0.8152 - val_accuracy: 0.7129\n",
      "Epoch 16/20\n",
      "1372/1372 - 9s - loss: 0.4392 - accuracy: 0.8400 - val_loss: 0.8543 - val_accuracy: 0.7110\n",
      "Epoch 17/20\n",
      "1372/1372 - 8s - loss: 0.4272 - accuracy: 0.8435 - val_loss: 0.8263 - val_accuracy: 0.7207\n",
      "Epoch 18/20\n",
      "1372/1372 - 9s - loss: 0.4105 - accuracy: 0.8496 - val_loss: 0.8451 - val_accuracy: 0.7194\n",
      "Epoch 19/20\n",
      "1372/1372 - 9s - loss: 0.4028 - accuracy: 0.8542 - val_loss: 0.9293 - val_accuracy: 0.6902\n",
      "Epoch 20/20\n",
      "1372/1372 - 9s - loss: 0.3912 - accuracy: 0.8566 - val_loss: 0.8641 - val_accuracy: 0.7235\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 20\n",
    "history = model.fit(train_padded, y_train, epochs=num_epochs, verbose=2, validation_split=.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict_proba(test_padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "array([[2.23496645e-05, 1.03462838e-01, 4.24345285e-02, 8.32242906e-01,\n",
       "        2.18374562e-02],\n",
       "       [3.54147702e-02, 5.59135199e-01, 9.02234390e-02, 8.84561241e-02,\n",
       "        2.26770446e-01],\n",
       "       [9.99983072e-01, 1.56119022e-05, 1.14379066e-08, 1.10233024e-10,\n",
       "        1.27408168e-06],\n",
       "       ...,\n",
       "       [8.16341781e-05, 9.99909282e-01, 8.04826428e-10, 1.95369262e-06,\n",
       "        7.13737518e-06],\n",
       "       [8.93631732e-05, 9.99848962e-01, 6.25036911e-09, 7.89445039e-07,\n",
       "        6.07830916e-05],\n",
       "       [9.99983191e-01, 4.34709727e-06, 4.26566839e-06, 1.91045029e-08,\n",
       "        8.23619757e-06]], dtype=float32)"
      ]
     },
     "metadata": {},
     "execution_count": 116
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19617, 5)"
      ]
     },
     "metadata": {},
     "execution_count": 117
    }
   ],
   "source": [
    "pred.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(19617, 500)"
      ]
     },
     "metadata": {},
     "execution_count": 118
    }
   ],
   "source": [
    "test_padded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "       index             0  ...             3             4\n",
       "0          0  2.234966e-05  ...  8.322429e-01  2.183746e-02\n",
       "1          1  3.541477e-02  ...  8.845612e-02  2.267704e-01\n",
       "2          2  9.999831e-01  ...  1.102330e-10  1.274082e-06\n",
       "3          3  8.926961e-07  ...  1.846117e-09  4.661073e-04\n",
       "4          4  9.257374e-01  ...  7.277032e-02  3.078114e-06\n",
       "...      ...           ...  ...           ...           ...\n",
       "19612  19612  1.330739e-07  ...  3.169428e-11  3.078867e-14\n",
       "19613  19613  2.404358e-04  ...  5.498563e-15  9.997405e-01\n",
       "19614  19614  8.163418e-05  ...  1.953693e-06  7.137375e-06\n",
       "19615  19615  8.936317e-05  ...  7.894450e-07  6.078309e-05\n",
       "19616  19616  9.999832e-01  ...  1.910450e-08  8.236198e-06\n",
       "\n",
       "[19617 rows x 6 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>index</th>\n      <th>0</th>\n      <th>1</th>\n      <th>2</th>\n      <th>3</th>\n      <th>4</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>2.234966e-05</td>\n      <td>1.034628e-01</td>\n      <td>4.243453e-02</td>\n      <td>8.322429e-01</td>\n      <td>2.183746e-02</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>1</td>\n      <td>3.541477e-02</td>\n      <td>5.591352e-01</td>\n      <td>9.022344e-02</td>\n      <td>8.845612e-02</td>\n      <td>2.267704e-01</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>2</td>\n      <td>9.999831e-01</td>\n      <td>1.561190e-05</td>\n      <td>1.143791e-08</td>\n      <td>1.102330e-10</td>\n      <td>1.274082e-06</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>3</td>\n      <td>8.926961e-07</td>\n      <td>1.792368e-12</td>\n      <td>9.995331e-01</td>\n      <td>1.846117e-09</td>\n      <td>4.661073e-04</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>4</td>\n      <td>9.257374e-01</td>\n      <td>1.335113e-04</td>\n      <td>1.355598e-03</td>\n      <td>7.277032e-02</td>\n      <td>3.078114e-06</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>19612</th>\n      <td>19612</td>\n      <td>1.330739e-07</td>\n      <td>9.999999e-01</td>\n      <td>8.891108e-21</td>\n      <td>3.169428e-11</td>\n      <td>3.078867e-14</td>\n    </tr>\n    <tr>\n      <th>19613</th>\n      <td>19613</td>\n      <td>2.404358e-04</td>\n      <td>1.468442e-05</td>\n      <td>4.297000e-06</td>\n      <td>5.498563e-15</td>\n      <td>9.997405e-01</td>\n    </tr>\n    <tr>\n      <th>19614</th>\n      <td>19614</td>\n      <td>8.163418e-05</td>\n      <td>9.999093e-01</td>\n      <td>8.048264e-10</td>\n      <td>1.953693e-06</td>\n      <td>7.137375e-06</td>\n    </tr>\n    <tr>\n      <th>19615</th>\n      <td>19615</td>\n      <td>8.936317e-05</td>\n      <td>9.998490e-01</td>\n      <td>6.250369e-09</td>\n      <td>7.894450e-07</td>\n      <td>6.078309e-05</td>\n    </tr>\n    <tr>\n      <th>19616</th>\n      <td>19616</td>\n      <td>9.999832e-01</td>\n      <td>4.347097e-06</td>\n      <td>4.265668e-06</td>\n      <td>1.910450e-08</td>\n      <td>8.236198e-06</td>\n    </tr>\n  </tbody>\n</table>\n<p>19617 rows Ã— 6 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 119
    }
   ],
   "source": [
    "sample_submission[[str(i) for i in range(5)]] = pred\n",
    "sample_submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample_submission.to_csv(\"submission.csv\", index=False, encoding=\"utf-8\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ]
}